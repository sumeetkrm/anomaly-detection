{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gmm recovery from a synthetic gmm\n",
    "# make a representative gmm\n",
    "def make_gmm(n_components, n_features, random_state=0):\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=random_state)\n",
    "    gmm.means_ = np.random.rand(n_components, n_features)\n",
    "    covariance_array = []\n",
    "    for i in range(n_components):\n",
    "        rand_matrix = np.random.rand(n_features, n_features)\n",
    "        covariance_array.append(np.dot(rand_matrix, rand_matrix.T))\n",
    "\n",
    "    gmm.covariances_ = np.array(covariance_array)\n",
    "\n",
    "    precision_array = [np.linalg.pinv(cov) for cov in covariance_array]\n",
    "    gmm.precisions_ = np.array(precision_array)\n",
    "    gmm.precisions_cholesky_ = np.array([np.linalg.cholesky(prec) for prec in precision_array])\n",
    "    \n",
    "    gmm.weights_ = np.random.rand(n_components)\n",
    "    gmm.weights_ /= np.sum(gmm.weights_)\n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[9.96106275, 6.67582311, 6.10926526, 7.96629442, 4.3538099 ,\n",
       "         6.56523486, 3.44828647, 4.73070603, 4.41565141, 4.81566433,\n",
       "         5.47509647, 1.9070171 , 6.47961543, 4.29270114, 5.41078108,\n",
       "         6.54905368, 2.46165833, 3.61818522, 6.70799447, 8.57542518]]),\n",
       " array([2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 5\n",
    "n_features = 20\n",
    "\n",
    "my_test_gmm = make_gmm(n_components, n_features)\n",
    "my_test_gmm.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10)\n",
      "(1000, 20)\n",
      "(10, 20)\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# take compressive meaurements\n",
    "# make 10 random measurement matrices\n",
    "n_measurements = ((n_features * 5) // 10) # 50% of the features\n",
    "\n",
    "measurement_matrices = []\n",
    "for i in range(10):\n",
    "    measurement_matrices.append(np.random.randn(n_measurements, n_features))\n",
    "\n",
    "# generate samples from the gmm\n",
    "n_samples = 1000\n",
    "samples = my_test_gmm.sample(n_samples)\n",
    "\n",
    "# take measurements\n",
    "compressed_measurements = []\n",
    "sample_measurement_matrix = []\n",
    "for i in range(n_samples):\n",
    "    matrix_index = np.random.randint(0, len(measurement_matrices))\n",
    "    sample_measurement_matrix.append(matrix_index)\n",
    "    compressed_measurements.append(np.dot(measurement_matrices[matrix_index], samples[0][i]))\n",
    "\n",
    "\n",
    "noise_std_dev = 0.05\n",
    "noise_covariance_matrix = np.eye(n_measurements) * (noise_std_dev * noise_std_dev)\n",
    "compressed_measurements = np.array(compressed_measurements)\n",
    "compressed_measurements += np.random.normal(0, noise_std_dev, compressed_measurements.shape)\n",
    "print(compressed_measurements.shape)\n",
    "print(samples[0].shape)\n",
    "print(measurement_matrices[0].shape)\n",
    "print(len(sample_measurement_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the 10 measurement matrices we have a separate gmm in the y-domain so let us make all of them p(y|z)\n",
    "\n",
    "def form_y_gmms(x_gmm, measurement_matrices, noise_covariance_matrix):\n",
    "    gmm_list = []\n",
    "    noise_inverse = np.linalg.inv(noise_covariance_matrix)\n",
    "    for i in range(len(measurement_matrices)):\n",
    "        gmm_sample = GaussianMixture(n_components=n_components, random_state=0)\n",
    "        gmm_sample.means_ = x_gmm.means_ @ measurement_matrices[i].T\n",
    "        covariance_array = []\n",
    "\n",
    "        for j in range(n_components):\n",
    "            C_ij = np.linalg.pinv(measurement_matrices[i].T @ noise_inverse @ measurement_matrices[i] + x_gmm.precisions_[j])\n",
    "            temp_matrix = noise_inverse @ measurement_matrices[i] @ C_ij @ measurement_matrices[i].T @ noise_inverse\n",
    "            covariance_array.append(np.linalg.pinv(noise_inverse - temp_matrix))\n",
    "\n",
    "        gmm_sample.covariances_ = np.array(covariance_array)\n",
    "        gmm_sample.weights_ = x_gmm.weights_\n",
    "\n",
    "        precision_array = [np.linalg.pinv(covariance_array[i]) for i in range(n_components)]\n",
    "        gmm_sample.precisions_ = np.array(precision_array)\n",
    "        gmm_sample.precisions_cholesky_ = np.array([np.linalg.cholesky(precision_array[i]) for i in range(n_components)])\n",
    "        \n",
    "        gmm_list.append(gmm_sample)\n",
    "    return gmm_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_likelihood(measurement_matrices, compressed_measurements, sample_measurement_matrix, gmm_list):\n",
    "    log_likelihood = 0\n",
    "    for i in range(compressed_measurements.shape[0]):\n",
    "        # print(gmm_list[sample_measurement_matrix[i]].score(compressed_measurements[i].reshape(1, -1)))\n",
    "        log_likelihood += gmm_list[sample_measurement_matrix[i]].score(compressed_measurements[i].reshape(1, -1))\n",
    "\n",
    "    return log_likelihood/len(compressed_measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_weights(compressed_measurements, y_gmms, sample_measurement_matrix):\n",
    "    # calculate p_ik\n",
    "    new_weights = []\n",
    "    for k in range(n_components):\n",
    "        ssum = 0\n",
    "        for i in range(n_samples):\n",
    "            p_ik = y_gmms[sample_measurement_matrix[i]].weights_[k] * multivariate_normal.pdf(compressed_measurements[i], mean=y_gmms[sample_measurement_matrix[i]].means_[k], cov=y_gmms[sample_measurement_matrix[i]].covariances_[k]) / np.exp(y_gmms[sample_measurement_matrix[i]].score(compressed_measurements[i].reshape(1, -1)))\n",
    "            ssum += p_ik\n",
    "        new_weights.append(ssum)\n",
    "    new_weights = np.array(new_weights)\n",
    "    new_weights /= np.sum(new_weights)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_reconstruction(measurement_matrix, noise_covariance_matrix, x_precision_matrix, x_mean, compressed_measurement):\n",
    "    \"\"\"\n",
    "    gets the x reconstruction for a compressed sample for the z^th component in x (specified by x_covariance_matrix and x_mean)\n",
    "    \"\"\"\n",
    "    noise_inverse = np.linalg.pinv(noise_covariance_matrix)\n",
    "    C_z = np.linalg.pinv(measurement_matrix.T @ noise_inverse @ measurement_matrix + x_precision_matrix)\n",
    "    x_reconstruction = x_mean + C_z @ measurement_matrix.T @ noise_inverse @ (compressed_measurement - measurement_matrix @ x_mean)\n",
    "    return x_reconstruction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_means(compressed_measurements, y_gmms, sample_measurement_matrix, estimated_gmm, measurement_matrices, noise_covariance_matrix):\n",
    "    new_means = []\n",
    "    for k in range(n_components):\n",
    "        ssum = 0\n",
    "        psum = 0\n",
    "        for i in range(n_samples):\n",
    "            p_ik = y_gmms[sample_measurement_matrix[i]].weights_[k] * multivariate_normal.pdf(compressed_measurements[i], mean=y_gmms[sample_measurement_matrix[i]].means_[k], cov=y_gmms[sample_measurement_matrix[i]].covariances_[k]) / np.exp(y_gmms[sample_measurement_matrix[i]].score(compressed_measurements[i].reshape(1, -1)))\n",
    "            psum += p_ik\n",
    "            n_ik = get_x_reconstruction(measurement_matrices[sample_measurement_matrix[i]], noise_covariance_matrix, estimated_gmm.precisions_[k], estimated_gmm.means_[k], compressed_measurements[i])\n",
    "            ssum += p_ik * n_ik\n",
    "        new_means.append(ssum/psum)\n",
    "    new_means = np.array(new_means)\n",
    "    return new_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_covariances(compressed_measurements, y_gmms, sample_measurement_matrix, estimated_gmm, measurement_matrices, noise_covariance_matrix, new_means):\n",
    "    new_covariances = []\n",
    "    for k in range(n_components):\n",
    "        csum = 0\n",
    "        psum = 0\n",
    "        for i in range(n_samples):\n",
    "            p_ik = y_gmms[sample_measurement_matrix[i]].weights_[k] * multivariate_normal.pdf(compressed_measurements[i], mean=y_gmms[sample_measurement_matrix[i]].means_[k], cov=y_gmms[sample_measurement_matrix[i]].covariances_[k]) / np.exp(y_gmms[sample_measurement_matrix[i]].score(compressed_measurements[i].reshape(1, -1)))\n",
    "            psum += p_ik\n",
    "            n_ik = get_x_reconstruction(measurement_matrices[sample_measurement_matrix[i]], noise_covariance_matrix, estimated_gmm.precisions_[k], estimated_gmm.means_[k], compressed_measurements[i])\n",
    "            C_ik = np.linalg.pinv(measurement_matrices[sample_measurement_matrix[i]].T @ np.linalg.pinv(noise_covariance_matrix) @ measurement_matrices[sample_measurement_matrix[i]] + estimated_gmm.precisions_[k])\n",
    "            csum += p_ik * (C_ik + (n_ik - new_means[k]).reshape(-1, 1) @ (n_ik - new_means[k]).reshape(1, -1))\n",
    "        new_covariances.append(csum/psum)\n",
    "    new_covariances = np.array(new_covariances)\n",
    "    return new_covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log likelihood:  -32.89812176828909\n",
      "Ideal log likelihood:  -30.84889044035522\n",
      "Iteration 1 log-likelihood: -31.84707499720047\n",
      "Iteration 2 log-likelihood: -31.57610682324713\n",
      "Iteration 3 log-likelihood: -31.431651140753964\n",
      "Iteration 4 log-likelihood: -31.334034693266776\n",
      "Iteration 5 log-likelihood: -31.261775000544326\n",
      "Iteration 6 log-likelihood: -31.20477622645312\n",
      "Iteration 7 log-likelihood: -31.156885467948406\n",
      "Converged\n"
     ]
    }
   ],
   "source": [
    "# initialise estimate of the original gmm\n",
    "# assumption is that we know the number of components required to model the original gmm\n",
    "estimated_gmm = make_gmm(n_components, n_features, random_state=7)\n",
    "\n",
    "# perform updates on the estimated gmm\n",
    "# log likelihoods stores the log likelihoods of the estimated gmm computed on the samples drawn from the original gmm, our objective is to maximise this\n",
    "tol = 0.05\n",
    "log_likelihoods = []\n",
    "y_gmms = form_y_gmms(estimated_gmm, measurement_matrices, noise_covariance_matrix)\n",
    "log_likelihoods.append(get_log_likelihood(measurement_matrices, compressed_measurements, sample_measurement_matrix, y_gmms))\n",
    "\n",
    "print(\"Initial log likelihood: \", log_likelihoods[-1])\n",
    "ideal_log_likelihood = get_log_likelihood(measurement_matrices, compressed_measurements, sample_measurement_matrix, form_y_gmms(my_test_gmm, measurement_matrices, noise_covariance_matrix))\n",
    "print(\"Ideal log likelihood: \", ideal_log_likelihood)\n",
    "\n",
    "noise_inverse =  np.linalg.inv(noise_covariance_matrix)\n",
    "iter_counter = 0\n",
    "\n",
    "while True:\n",
    "    # perform updates\n",
    "    # for each of the 10 measurement matrices we have a separate gmm in the y-domain so let us make all of them\n",
    "    # update weights\n",
    "    # new_weights = []\n",
    "    # for i in range(n_components):\n",
    "    #     ssum = 0\n",
    "    #     for j in range(len(compressed_measurements)):\n",
    "    #         den = 0\n",
    "    #         for k in range(n_components):\n",
    "    #             den += estimated_gmm.weights_[k] * multivariate_normal.pdf(compressed_measurements[j], mean=y_gmms[sample_measurement_matrix[j]].means_[k], cov=y_gmms[sample_measurement_matrix[j]].covariances_[k])\n",
    "    #         ssum += estimated_gmm.weights_[i] * multivariate_normal.pdf(compressed_measurements[j], mean=y_gmms[sample_measurement_matrix[j]].means_[i], cov=y_gmms[sample_measurement_matrix[j]].covariances_[i]) / den\n",
    "    #     new_weights.append(ssum) # entry appended was \\sum_{i = 1}^{N} p_ik for k as the iter counter (here 'i')\n",
    "    # new_weights = np.array(new_weights)\n",
    "    # # new_weights /= np.sum(new_weights) # do this after mean and covariance update\n",
    "\n",
    "    # # update means\n",
    "    # new_means = []\n",
    "    # for i in range(n_components):\n",
    "    #     ssum = 0\n",
    "    #     psum = 0\n",
    "    #     for j in range(len(compressed_measurements)):\n",
    "    #         den = 0\n",
    "    #         for k in range(n_components):\n",
    "    #             den += estimated_gmm.weights_[k] * multivariate_normal.pdf(compressed_measurements[j], mean=y_gmms[sample_measurement_matrix[j]].means_[k], cov=y_gmms[sample_measurement_matrix[j]].covariances_[k])\n",
    "    #         p_ik = estimated_gmm.weights_[i] * multivariate_normal.pdf(compressed_measurements[j], mean=y_gmms[sample_measurement_matrix[j]].means_[i], cov=y_gmms[sample_measurement_matrix[j]].covariances_[i]) / den\n",
    "    #         C_ik = np.linalg.pinv(measurement_matrices[sample_measurement_matrix[j]].T @ noise_inverse @ measurement_matrices[sample_measurement_matrix[j]] + estimated_gmm.precisions_[i])\n",
    "    #         n_ik = estimated_gmm.means_[i] + (C_ik @ measurement_matrices[sample_measurement_matrix[j]].T @ noise_inverse @ (compressed_measurements[j] - measurement_matrices[sample_measurement_matrix[j]] @ estimated_gmm.means_[i]))\n",
    "    #         ssum += p_ik * n_ik\n",
    "    #         psum += p_ik\n",
    "    #     new_means.append(ssum / psum)\n",
    "\n",
    "    # # update covariances\n",
    "    # new_covariances = []\n",
    "    # for i in range(n_components):\n",
    "    #     ssum = 0\n",
    "    #     psum = 0\n",
    "    #     for j in range(len(compressed_measurements)):\n",
    "    #         den = 0\n",
    "    #         for k in range(n_components):\n",
    "    #             den += y_gmms[sample_measurement_matrix[j]].weights_[k] * multivariate_normal.pdf(compressed_measurements[j], mean=y_gmms[sample_measurement_matrix[j]].means_[k], cov=y_gmms[sample_measurement_matrix[j]].covariances_[k])\n",
    "    #         p_ik = y_gmms[sample_measurement_matrix[j]].weights_[i] * multivariate_normal.pdf(compressed_measurements[j], mean=y_gmms[sample_measurement_matrix[j]].means_[i], cov=y_gmms[sample_measurement_matrix[j]].covariances_[i]) / den\n",
    "    #         C_ik = np.linalg.pinv((measurement_matrices[sample_measurement_matrix[j]].T @ noise_inverse @ measurement_matrices[sample_measurement_matrix[j]]) + estimated_gmm.precisions_[i])\n",
    "    #         n_ik = estimated_gmm.means_[i] + C_ik @ (measurement_matrices[sample_measurement_matrix[j]].T @ noise_inverse @ (compressed_measurements[j] - measurement_matrices[sample_measurement_matrix[j]] @ estimated_gmm.means_[i]))\n",
    "    #         ssum += p_ik * ((n_ik - new_means[i]) @ (n_ik - new_means[i]).T + C_ik)\n",
    "    #         psum += p_ik\n",
    "    #     new_covariances.append(ssum / psum)\n",
    "\n",
    "\n",
    "    estimated_gmm.weights_ = get_new_weights(compressed_measurements, y_gmms, sample_measurement_matrix)\n",
    "    estimated_gmm.means_ = get_new_means(compressed_measurements, y_gmms, sample_measurement_matrix, estimated_gmm, measurement_matrices, noise_covariance_matrix)\n",
    "    estimated_gmm.covariances_ = get_new_covariances(compressed_measurements, y_gmms, sample_measurement_matrix, estimated_gmm, measurement_matrices, noise_covariance_matrix, estimated_gmm.means_)\n",
    "    precision_array = [np.linalg.pinv(cov) for cov in estimated_gmm.covariances_]\n",
    "    estimated_gmm.precisions_ = np.array(precision_array)\n",
    "    estimated_gmm.precisions_cholesky_ = np.array([np.linalg.cholesky(prec) for prec in estimated_gmm.precisions_])\n",
    "\n",
    "    y_gmms = form_y_gmms(estimated_gmm, measurement_matrices, noise_covariance_matrix)\n",
    "    log_likelihoods.append(get_log_likelihood(measurement_matrices, compressed_measurements, sample_measurement_matrix, y_gmms))\n",
    "    print(f\"Iteration {iter_counter + 1} log-likelihood: {log_likelihoods[-1]}\")\n",
    "    iter_counter += 1\n",
    "    if abs(log_likelihoods[-1] - log_likelihoods[-2]) < tol or log_likelihoods[-1] > ideal_log_likelihood:\n",
    "        if abs(log_likelihoods[-1] - log_likelihoods[-2]) < tol:\n",
    "            print(\"Converged\")\n",
    "        else:\n",
    "            print(\"Ideal log-likelihood reached, stopping to avoid overfitting\")\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
